{
  "paragraphs": [
    {
      "title": "",
      "text": "%md\n\n# Uploading Data\n\nThis topic describes how to upload data into ZEPL, and analyze it using Spark, Python, or other interpreters within ZEPL.",
      "user": "",
      "dateUpdated": "2019-03-24 10:20:19.000",
      "config": {
        "selectedInterpreter": {
          "name": "md",
          "profile": "md",
          "isCustom": false,
          "editorLanguage": "markdown",
          "className": "org.apache.zeppelin.markdown.Markdown",
          "isDefault": true
        },
        "colWidth": 12.0,
        "editorHide": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eUploading Data\u003c/h1\u003e\n\u003cp\u003eThis topic describes how to upload data into ZEPL, and analyze it using Spark, Python, or other interpreters within ZEPL.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20190324-102019_152685498",
      "dateCreated": "2019-03-24 10:20:19.000",
      "dateStarted": "2019-04-01 05:11:51.000",
      "dateFinished": "2019-04-01 05:11:51.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%md\n\n## Import data\n\nIf you have files (up to 100MB size) on your local machine that you want to analyze with ZEPL, you can upload the file by clicking on the right menu bar in your notebook and choosing the **Upload** button, or by simply dragging and dropping the relevant file into the sidebar. Once uploaded, the file(s) are only accessible through the given notebook.",
      "user": "",
      "dateUpdated": "2019-03-24 10:20:19.000",
      "config": {
        "selectedInterpreter": {
          "name": "md",
          "profile": "md",
          "isCustom": false,
          "editorLanguage": "markdown",
          "className": "org.apache.zeppelin.markdown.Markdown",
          "isDefault": true
        },
        "colWidth": 12.0,
        "editorHide": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eImport data\u003c/h2\u003e\n\u003cp\u003eIf you have files (up to 100MB size) on your local machine that you want to analyze with ZEPL, you can upload the file by clicking on the right menu bar in your notebook and choosing the \u003cstrong\u003eUpload\u003c/strong\u003e button, or by simply dragging and dropping the relevant file into the sidebar. Once uploaded, the file(s) are only accessible through the given notebook.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20190324-102019_1864100069",
      "dateCreated": "2019-03-24 10:20:19.000",
      "dateStarted": "2019-04-01 05:11:51.000",
      "dateFinished": "2019-04-01 05:11:51.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%md\n\n## Load data\n\nOnce the file is uploaded to the notebook, you can access the file by the following URL (where the **\u0026lt;file-name\u0026gt;** is the name of the file):\n\n```\nhttp://zdata/\u003cfile-name\u003e\n```",
      "user": "",
      "dateUpdated": "2019-03-24 10:20:19.000",
      "config": {
        "selectedInterpreter": {
          "name": "md",
          "profile": "md",
          "isCustom": false,
          "editorLanguage": "markdown",
          "className": "org.apache.zeppelin.markdown.Markdown",
          "isDefault": true
        },
        "colWidth": 12.0,
        "editorHide": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eLoad data\u003c/h2\u003e\n\u003cp\u003eOnce the file is uploaded to the notebook, you can access the file by the following URL (where the \u003cstrong\u003e\u0026lt;file-name\u0026gt;\u003c/strong\u003e is the name of the file):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehttp://zdata/\u0026lt;file-name\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20190324-102019_941037003",
      "dateCreated": "2019-03-24 10:20:19.000",
      "dateStarted": "2019-04-01 05:11:51.000",
      "dateFinished": "2019-04-01 05:11:51.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "Scala",
      "text": "%spark\n\nimport org.apache.spark.SparkFiles\n\nsc.addFile(\"http://zdata/bank.csv\")\nval sparkDF \u003d spark.read.format(\"csv\")\n  .option(\"delimiter\", \";\")\n  .option(\"header\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .load(SparkFiles.get(\"bank.csv\"))",
      "user": "",
      "dateUpdated": "2019-04-01 05:10:07.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark",
          "profile": "spark",
          "isCustom": false,
          "editorLanguage": "scala",
          "className": "org.apache.zeppelin.spark.SparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "title": true,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "data": "java.lang.IllegalArgumentException: Illegal pattern component: XXX\n  at org.apache.commons.lang3.time.FastDateFormat.parsePattern(FastDateFormat.java:577)\n  at org.apache.commons.lang3.time.FastDateFormat.init(FastDateFormat.java:444)\n  at org.apache.commons.lang3.time.FastDateFormat.\u003cinit\u003e(FastDateFormat.java:437)\n  at org.apache.commons.lang3.time.FastDateFormat$1.createInstance(FastDateFormat.java:110)\n  at org.apache.commons.lang3.time.FastDateFormat$1.createInstance(FastDateFormat.java:109)\n  at org.apache.commons.lang3.time.FormatCache.getInstance(FormatCache.java:82)\n  at org.apache.commons.lang3.time.FastDateFormat.getInstance(FastDateFormat.java:205)\n  at org.apache.spark.sql.execution.datasources.csv.CSVOptions.\u003cinit\u003e(CSVOptions.scala:128)\n  at org.apache.spark.sql.execution.datasources.csv.CSVOptions.\u003cinit\u003e(CSVOptions.scala:39)\n  at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:55)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$7.apply(DataSource.scala:178)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$7.apply(DataSource.scala:178)\n  at scala.Option.orElse(Option.scala:289)\n  at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:177)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:353)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:156)\n  ... 47 elided\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20190324-102019_1725097513",
      "dateCreated": "2019-03-24 10:20:19.000",
      "dateStarted": "2019-04-01 05:10:06.909",
      "dateFinished": "2019-04-01 05:10:07.293",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "PySpark",
      "text": "%spark.pyspark\n\nfrom pyspark import SparkFiles\n\nsc.addFile(\u0027http://zdata/bank.csv\u0027)\nsparkDF \u003d spark.read.format(\u0027csv\u0027).options(delimiter\u003d\u0027;\u0027, header\u003d\u0027true\u0027, inferSchema\u003d\u0027true\u0027).load(SparkFiles.get(\u0027bank.csv\u0027))",
      "user": "",
      "dateUpdated": "2019-03-24 10:20:19.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "title": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20190324-102019_813970903",
      "dateCreated": "2019-03-24 10:20:19.000",
      "dateStarted": "2019-04-01 05:11:51.000",
      "dateFinished": "2019-04-01 05:11:51.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "SparkR",
      "text": "%spark.r\n\nspark.addFile(\"http://zdata/bank.csv\")\nsparkDF \u003c- read.df(path \u003d spark.getSparkFiles(\"bank.csv\"), source \u003d \"csv\", delimiter \u003d \";\", header \u003d \"true\", inferSchema \u003d \"true\")",
      "user": "",
      "dateUpdated": "2019-03-24 10:20:19.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.r",
          "profile": "r",
          "isCustom": false,
          "editorLanguage": "r",
          "className": "org.apache.zeppelin.spark.SparkRInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "title": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20190324-102019_1446496289",
      "dateCreated": "2019-03-24 10:20:19.000",
      "dateStarted": "2019-04-01 05:11:51.000",
      "dateFinished": "2019-04-01 05:11:51.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "Python",
      "text": "%python\n\nimport pandas as pd\npandas_df \u003d pd.read_csv(\u0027http://zdata/bank.csv\u0027, sep\u003d\u0027;\u0027, header\u003d\u0027infer\u0027)",
      "user": "",
      "dateUpdated": "2019-03-24 10:20:19.000",
      "config": {
        "selectedInterpreter": {
          "name": "python",
          "profile": "python",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.python.PythonInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "title": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20190324-102019_967275034",
      "dateCreated": "2019-03-24 10:20:19.000",
      "dateStarted": "2019-04-01 05:11:51.000",
      "dateFinished": "2019-04-01 05:11:51.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%md\n\n## Download data\n\nIf the data volume is small enough, you can also load this data directly onto the container. You can use `%python !wget http://zdata/\u003cfile-name\u003e` to download data to the container. Once the file is downloaded to the container, you can access the downloaded file as a local file.",
      "user": "",
      "dateUpdated": "2019-03-24 10:20:19.000",
      "config": {
        "selectedInterpreter": {
          "name": "md",
          "profile": "md",
          "isCustom": false,
          "editorLanguage": "markdown",
          "className": "org.apache.zeppelin.markdown.Markdown",
          "isDefault": true
        },
        "colWidth": 12.0,
        "editorHide": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eDownload data\u003c/h2\u003e\n\u003cp\u003eIf the data volume is small enough, you can also load this data directly onto the container. You can use \u003ccode\u003e%python !wget http://zdata/\u0026lt;file-name\u0026gt;\u003c/code\u003e to download data to the container. Once the file is downloaded to the container, you can access the downloaded file as a local file.\u003c/p\u003e\n\u003c/div\u003e",
            "type": "HTML"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20190324-102019_982500142",
      "dateCreated": "2019-03-24 10:20:19.000",
      "dateStarted": "2019-04-01 05:11:51.000",
      "dateFinished": "2019-04-01 05:11:51.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%python\n!wget http://zdata/bank.csv\n\nimport pandas as pd\npandas_df \u003d pd.read_csv(\u0027bank.csv\u0027, sep\u003d\u0027;\u0027, header\u003d\u0027infer\u0027)",
      "user": "",
      "dateUpdated": "2019-03-24 10:20:19.000",
      "config": {
        "selectedInterpreter": {
          "name": "python",
          "profile": "python",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.python.PythonInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "title": false,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20190324-102019_108016493",
      "dateCreated": "2019-03-24 10:20:19.000",
      "dateStarted": "2019-04-01 05:11:51.000",
      "dateFinished": "2019-04-01 05:11:51.000",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    }
  ],
  "name": "Uploading Data",
  "id": "uploading_data",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {},
  "info": {}
}
